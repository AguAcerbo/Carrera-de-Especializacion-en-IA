{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3463f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import pickle as pkl\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382e8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361f83ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r\"C:\\Users\\Agustin\\Documents\\RepositorioCEIA_Git\\VpC2_Datasets\\severstal-steel-defect-detection/train.csv\"\n",
    "train_path = r\"C:\\Users\\Agustin\\Documents\\RepositorioCEIA_Git\\VpC2_Datasets\\severstal-steel-defect-detection/train_images/\"\n",
    "train_masks_path = r\"C:\\Users\\Agustin\\Documents\\RepositorioCEIA_Git\\VpC2_Datasets\\severstal-steel-defect-detection/train_masks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5436fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b41764",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = listdir(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179aff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_h = 256\n",
    "n_w = 1600\n",
    "n_class = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549e9e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_layer, start_neurons):\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(0.25)(pool1)\n",
    "\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(0.5)(pool2)\n",
    "\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(0.5)(pool3)\n",
    "\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(pool3)\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(0.5)(pool4)\n",
    "\n",
    "    # Mitad\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(pool4)\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(convm)\n",
    "    \n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(0.5)(uconv4)\n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n",
    "\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])\n",
    "    uconv3 = Dropout(0.5)(uconv3)\n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n",
    "\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "    uconv2 = Dropout(0.5)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    uconv1 = Dropout(0.5)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "    \n",
    "    output_layer = Conv2D(5, (1,1), padding=\"same\", activation=\"softmax\")(uconv1)\n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "input_layer = Input((256, 1600, 3))\n",
    "output_layer = build_model(input_layer, 16)\n",
    "\n",
    "model = Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276e9256",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=sparse_categorical_crossentropy, optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbba1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b936d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    )\n",
    "\n",
    "mask_datagen = ImageDataGenerator(\n",
    "    )\n",
    "\n",
    "\n",
    "image_generator = train_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\Agustin\\Documents\\RepositorioCEIA_Git\\VpC2_Datasets\\severstal-steel-defect-detection/',\n",
    "        target_size=(n_h, n_w),\n",
    "        batch_size=8,\n",
    "        shuffle=False,\n",
    "        color_mode=\"rgb\",\n",
    "        classes=['train_images'],\n",
    "        class_mode=None)\n",
    "\n",
    "mask_generator = mask_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\Agustin\\Documents\\RepositorioCEIA_Git\\VpC2_Datasets\\severstal-steel-defect-detection/',\n",
    "        target_size=(n_h, n_w),\n",
    "        batch_size=8,\n",
    "        shuffle=False,\n",
    "        color_mode=\"grayscale\",\n",
    "        classes=['train_masks'], \n",
    "        class_mode=None)\n",
    "\n",
    "train_generator = zip(image_generator, mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e1f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(\"./keras.model\", save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n",
    "\n",
    "epochs = 10\n",
    "steps_per_epoch=int(len(train_files)/8)\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=epochs,\n",
    "                    #callbacks=[early_stopping, model_checkpoint, reduce_lr])\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15612819",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a5405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict(image_generator[7])\n",
    "np.max(np.argmax(prediction,axis=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722eb4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
