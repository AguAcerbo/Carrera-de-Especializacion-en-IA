{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70cfba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch # Libreria\n",
    "from torch.utils.data import Dataset # Clase u objeto que va a contener la informacion que vamos a utilizar para entrenar y evaluar nuestro algoritmo\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7561cf",
   "metadata": {},
   "source": [
    "## Uso de GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b795adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d526d667",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "    print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477f7412",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Device: \",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d332ba",
   "metadata": {},
   "source": [
    "## Normalizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a3c604",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = (final_dataset - np.min(final_dataset, axis=0)) / (np.max(final_dataset, axis=0) - np.min(final_dataset, axis=0))\n",
    "print(np.max(normalized_data, axis=0))\n",
    "print(np.min(normalized_data, axis=0))\n",
    "print(normalized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4470e71c",
   "metadata": {},
   "source": [
    "## CustomDataset y DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeedf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx,:], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ac1b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = CustomDataset(x_train, l_train)\n",
    "print(training_set.__len__())\n",
    "print(training_set.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956a03ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = CustomDataset(x_test, l_test)\n",
    "print(test_set.__len__())\n",
    "print(test_set.__getitem__(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c436e17a",
   "metadata": {},
   "source": [
    "El **DataLoader** simpre espera el set de datos, el batch_size que preferentemente deberia ser potencia de 2 para optimizar los calculos, y opcional el shuffel que mezcla los datos cada vez que comienza una epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5cfb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training_set, batch_size = 512, shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size = 256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846b3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_dataloader) # Muestra el tamaÃ±o de cada batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bc458e",
   "metadata": {},
   "source": [
    "## Regresion Logistica Bivariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29804ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el modelo\n",
    "class NNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_1 = torch.nn.Linear(in_features = 2, out_features = 10, bias = True)\n",
    "        self.sigmoid_1 = torch.nn.ReLU()\n",
    "        self.linear_2 = torch.nn.Linear(in_features = 10, out_features = 20, bias = True)\n",
    "        self.sigmoid_2 = torch.nn.ReLU()\n",
    "        self.linear_3 = torch.nn.Linear(in_features = 20, out_features = 1, bias = True)\n",
    "        self.sigmoid_3 = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "                                    # x.shape = 512 x 2\n",
    "        z1 = self.linear_1(x)       # z1.shape = 512 x 10\n",
    "        a1 = self.relu_1(z1)        # a1.shape = 512 x 10\n",
    "        z2 = self.linear_2(a1)      # z2.shape = 512 x 20 \n",
    "        a2 = self.relu_2(z2)        # a2.shape = 512 x 20\n",
    "        z3 = self.linear_3(a2)      # z3.shape = 512 x 1 -> [-inf, +inf]\n",
    "        y = self.relu_3(z3)         # y.shape = 512 x 1 -> [0, 1]\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0295d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = NNet()\n",
    "print(nnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af80704",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss(reduction='sum') # criterion, is my lost fuction\n",
    "optimizer = torch.optim.SGD(nnet.parameters(), lr=0.005) # is my optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e37920",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(training_dataloader):\n",
    "        # data\n",
    "        x, y = data\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device).float().reshape(-1,1)\n",
    "\n",
    "        # set gradient to zero\n",
    "        optimizer.zero_grad()  #pytorch requiere que inicializemos en cada corrida los gradientes\n",
    "\n",
    "        #forward\n",
    "        y_hat = nnet(x)\n",
    "\n",
    "        #loss\n",
    "        loss = criterion(y_hat, y)\n",
    "\n",
    "        #backward\n",
    "        loss.backward()\n",
    "\n",
    "        #update of parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        #compute metrics and statistics\n",
    "        running_loss += loss.item()\n",
    "  \n",
    "    print(f\"Epoch = {epoch} - loss = {running_loss / len(training_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71b42b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(test_dataloader):\n",
    "    # compute metrics\n",
    "    # precision, recall,  acc, f1\n",
    "    # use scikit learn\n",
    "  \n",
    "    # data\n",
    "    x_tst, y_tst = data\n",
    "    x_tst = x_tst.to(device).float()\n",
    "    #y_tst = y_tst.to(device).float().reshape(-1,1)\n",
    "\n",
    "    y_hat_test = (nnet(x_tst).detach().numpy() >= 0.5)\n",
    "\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_tst, y_hat_test))\n",
    "    print(\"Precision:\",metrics.precision_score(y_tst, y_hat_test))\n",
    "    print(\"Recall:\",metrics.recall_score(y_tst, y_hat_test))\n",
    "    print(\"F1:\",metrics.f1_score(y_tst, y_hat_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba3109f",
   "metadata": {},
   "source": [
    "## Regresion Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd896c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el modelo\n",
    "class NNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_1 = torch.nn.Linear(in_features = 2, out_features = 100, bias = True)\n",
    "        self.dropout_1 = torch.nn.Dropout(p=0.5)\n",
    "        self.relu_1 = torch.nn.ReLU()\n",
    "        self.linear_2 = torch.nn.Linear(in_features = 100, out_features = 500, bias = True)\n",
    "        self.dropout_2 = torch.nn.Dropout(p=0.25)\n",
    "        self.relu_2 = torch.nn.ReLU()\n",
    "        self.linear_3 = torch.nn.Linear(in_features = 500, out_features = 800, bias = True)\n",
    "        self.dropout_3 = torch.nn.Dropout(p=0.25)\n",
    "        self.relu_3 = torch.nn.ReLU()\n",
    "        self.linear_4 = torch.nn.Linear(in_features = 800, out_features = 200, bias = True)\n",
    "        self.dropout_4 = torch.nn.Dropout(p=0.5)\n",
    "        self.relu_4 = torch.nn.ReLU()\n",
    "        self.linear_5 = torch.nn.Linear(in_features = 200, out_features = 1, bias = True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "                                    \n",
    "        z1 = self.linear_1(x)\n",
    "        z1_1 = self.dropout_1(z1)\n",
    "        a1 = self.relu_1(z1_1)\n",
    "        z2 = self.linear_2(a1)\n",
    "        z2_1 = self.dropout_2(z2)\n",
    "        a2 = self.relu_2(z2_1)\n",
    "        z3 = self.linear_3(a2)\n",
    "        z3_1 = self.dropout_3(z3)\n",
    "        a3 = self.relu_3(z3_1)\n",
    "        z4 = self.linear_4(a3)\n",
    "        z4_1 = self.dropout_4(z4)\n",
    "        a4 = self.relu_4(z4_1)\n",
    "        y = self.linear_5(a4)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cb1208",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = NNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee5341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ad1c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.SGD(nnet.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b8d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec22d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(training_dataloader):\n",
    "        # data\n",
    "        x, y = data\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device).float().reshape(-1,1)\n",
    "        \n",
    "        # set gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #forward\n",
    "        y_hat = nnet(x).reshape(-1,1)\n",
    "\n",
    "        #loss\n",
    "        loss = criterion(y_hat, y)\n",
    "\n",
    "        #backward\n",
    "        loss.backward()\n",
    "\n",
    "        #update of parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        #compute metrics and statistics\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    nnet.eval()\n",
    "    with torch.no_grad():\n",
    "        nnet_test_scores = []\n",
    "        truth = []\n",
    "        \n",
    "        for i, data in enumerate(test_dataloader):\n",
    "            #batch\n",
    "            x, y = data\n",
    "            x = x.to(device).float()\n",
    "            y = y.to(device).float().reshape(-1,1)\n",
    "        \n",
    "            # forward \n",
    "            y_hat = nnet(x)\n",
    "        \n",
    "            # accumulate data\n",
    "            truth = list(y.cpu().detach().numpy()) \n",
    "            nnet_test_scores = list(y_hat.cpu().detach().numpy())\n",
    "            \n",
    "        mse = metrics.mean_squared_error(truth, nnet_test_scores)\n",
    "        \n",
    "    print(f\"Epoch = {epoch} - loss = {running_loss / len(training_set)} - mse: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9a8dae",
   "metadata": {},
   "source": [
    "## Regresion Logistica Bivariada con Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732e0c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento similar para la variable vendor id\n",
    "print(ds.vendor_id.unique())\n",
    "print(len(ds.vendor_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b62290",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDatasetWithEmbedding(Dataset):\n",
    "    def __init__(self, X, vendor_idx, Y):\n",
    "        super().__init__()\n",
    "        self.vendor_idx = vendor_idx\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx,:], self.vendor_idx[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6a6b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = CustomDatasetWithEmbedding(X_train, vendor_index_train, y_train)\n",
    "testing = CustomDatasetWithEmbedding(X_test, vendor_index_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58192bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(testing, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c8970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNet(torch.nn.Module):\n",
    "    def __init__(self, number_of_vendors, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=number_of_vendors, embedding_dim=embedding_dim)\n",
    "        self.linear_1 = torch.nn.Linear(in_features=(13 + embedding_dim), out_features=200, bias=True)\n",
    "        self.relu_1 = torch.nn.ReLU()\n",
    "        self.linear_2 = torch.nn.Linear(in_features=200, out_features=100, bias=True)\n",
    "        self.relu_2 = torch.nn.ReLU()\n",
    "        self.linear_3 = torch.nn.Linear(in_features=100, out_features=1, bias=True)\n",
    "    \n",
    "    def forward(self, x, vendor_idx):\n",
    "        vendor_emb = self.embedding(vendor_idx)\n",
    "        final_input = torch.cat([x, vendor_emb], dim=1)\n",
    "        z1 = self.linear_1(final_input)\n",
    "        a1 = self.relu_1(z1)\n",
    "        z2 = self.linear_2(a1)\n",
    "        a2 = self.relu_2(z2)\n",
    "        y = self.linear_3(a2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7499bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = NNet(number_of_vendors=len(unique), embedding_dim=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f744873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af263eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum') # criterion, is my lost function\n",
    "optimizer = torch.optim.Adam(nnet.parameters(), lr=0.01) # is my optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cae6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet.to(device)\n",
    "\n",
    "for epoch in range(20):\n",
    "\n",
    "    running_loss = 0\n",
    "    nnet.train()\n",
    "    for i, data in enumerate(training_dataloader):\n",
    "\n",
    "        # batch\n",
    "        x, vendor_idx, y = data\n",
    "\n",
    "        #vendor_idx = vendor_idx.to(device).reshape(-1,1)\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device).float().reshape(-1,1)\n",
    "\n",
    "        # set gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        y_hat = nnet(x, vendor_idx)\n",
    "\n",
    "        # loss\n",
    "        loss = criterion(y_hat, y)\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "\n",
    "        # update of parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # compute metrics and statistics\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    nnet.eval()\n",
    "    with torch.no_grad():\n",
    "        nnet_test_scores = []\n",
    "        truth = []\n",
    "        for i, data in enumerate(test_dataloader):\n",
    "            # batch\n",
    "            x, vendor_idx, y = data\n",
    "            x = x.to(device).float()\n",
    "            y = y.to(device).float().reshape(-1,1)\n",
    "\n",
    "            # forward \n",
    "            y_hat = nnet(x, vendor_idx)\n",
    "            y_hat = torch.sigmoid(y_hat)\n",
    "\n",
    "            # accumulate data\n",
    "            truth += list(y.detach().numpy()) \n",
    "            nnet_test_scores += list(y_hat.detach().numpy())\n",
    "\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(truth, nnet_test_scores)\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "        print(f\"Epoch = {epoch} | loss = {running_loss / len(training)} | auc = {auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1423e9",
   "metadata": {},
   "source": [
    "## Clasificacion (Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2791e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_1 = torch.nn.Linear(in_features=2, out_features=10, bias = True)\n",
    "        self.activation_1 = torch.nn.ReLU()\n",
    "        self.dropout_1= torch.nn.Dropout(p=0.05)\n",
    "        self.linear_2 = torch.nn.Linear(in_features=10, out_features=20, bias = True)\n",
    "        self.activation_2 = torch.nn.ReLU()\n",
    "        self.dropout_2= torch.nn.Dropout(p=0.05)\n",
    "        self.linear_3 = torch.nn.Linear(in_features=20, out_features=4, bias = True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # X es el batch que va a entrar\n",
    "        z1 = self.linear_1(x)\n",
    "        a1 = self.activation_1(z1)\n",
    "        d1 = self.dropout_1(a1)\n",
    "        z2 = self.linear_2(d1)\n",
    "        a2 = self.activation_2(z2)\n",
    "        d2 = self.dropout_2(a2)\n",
    "        y = self.linear_3(d2)     \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78ccbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(nnet.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb60f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3f9f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f5e477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
