{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AguAcerbo/DeepLearning/blob/main/Clase_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lUCc8KvXktX7"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPgDxE5tnWIL"
   },
   "source": [
    "EJEMPLO NO LINEAL FUNCION XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwbsN-AcVFV6",
    "outputId": "c004d3e0-fe7e-4921-bf46-cf67c7c7094b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]]) \n",
    "# a la tabla de la verdad de la xor se le agrega una columna de unos de modo de adicionar la ordenada al origen\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lTqehalckeJs",
    "outputId": "8fa32f36-05ef-4d71-ee56-683ce2937dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([0,1,1,0])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yaF-1JAzkoKM",
    "outputId": "fa0bc4df-a849-476d-eeeb-c9d9aa26adea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.66533454e-16, 5.55111512e-17, 5.00000000e-01])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = (np.linalg.inv(x.T @ x)) @ x.T @ y\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOlBwdUnmLTk"
   },
   "source": [
    "Esto es un ejemplo de porque a veces necesitamos modelos no lineales. En este caso la funcion XOR no es lineal y nuestro modelo lo trata de manera lineal por lo que la optimizacion llega a obtener un valor $w_0=0.5$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsGUWVGdk__1"
   },
   "source": [
    "## Modelizado No Lineal de compuertas logicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "        return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsig(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferencia\n",
    "def test(x, y, w11_1, w12_1, b1_1, w21_1, w22_1, b2_1, w11_2, w12_2, b1_2):\n",
    "    J = 0\n",
    "    \n",
    "    for sample in range(x.shape[0]):\n",
    "        z1_1 = w11_1 * x[sample,1] + w12_1 * x[sample,0] + b1_1\n",
    "        a1_1 = sigmoid(z1_1)\n",
    "            \n",
    "        z2_1 = w21_1 * x[sample,1] + w22_1 * x[sample,0] + b2_1\n",
    "        a2_1 = sigmoid(z2_1)\n",
    "            \n",
    "        z1_2 = w11_2 * a1_1 + w12_2 * a2_1 + b1_2\n",
    "        y_hat = z1_2\n",
    "        J += (y[sample]-y_hat)**2\n",
    "        print(f\"Valor real: {y[sample]}\\tPrediccion: {np.around(y_hat)}\\tError: {J}\")\n",
    "    print(f\"Error del modelo {J/x.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logic_gates_model(x, y, epochs=1000, lr=0.1, eps = 1):\n",
    "    \n",
    "    # Params Neurona 1 Layer 1\n",
    "    w11_1 = (np.random.rand() * (2*eps) - eps)\n",
    "    w12_1 = (np.random.rand() * (2*eps) - eps)\n",
    "    b1_1 = (np.random.rand() * (2*eps) - eps)\n",
    "\n",
    "    # Params Neurona 2 Layer 1\n",
    "    w21_1 = (np.random.rand() * (2*eps) - eps)\n",
    "    w22_1 = (np.random.rand() * (2*eps) - eps)\n",
    "    b2_1 = (np.random.rand() * (2*eps) - eps)\n",
    "\n",
    "    # Params Neurona 1 Layer 2\n",
    "    w11_2 = (np.random.rand() * (2*eps) - eps)\n",
    "    w12_2 = (np.random.rand() * (2*eps) - eps)\n",
    "    b1_2 = (np.random.rand() * (2*eps) - eps)\n",
    "\n",
    "    for epoch in range(epochs): # loop in epochs\n",
    "        index = np.random.permutation(x.shape[0])\n",
    "        x = x[index, :]\n",
    "        y = y[index]\n",
    "        for sample in range(x.shape[0]): # loop in barches\n",
    "            #*****Forward*****\n",
    "            # Neurona 1 Layer 1\n",
    "            z1_1 = w11_1 * x[sample,1] + w12_1 * x[sample,0] + b1_1\n",
    "            a1_1 = sigmoid(z1_1)\n",
    "\n",
    "            # Neurona 2 Layer 1\n",
    "            z2_1 = w21_1 * x[sample,1] + w22_1 * x[sample,0] + b2_1\n",
    "            a2_1 = sigmoid(z2_1)\n",
    "\n",
    "            # Neurona 1 Layer 2\n",
    "            z1_2 = w11_2 * a1_1 + w12_2 * a2_1 + b1_2\n",
    "            #a1_2 = sigmoid(z1_2)\n",
    "            y_hat = z1_2\n",
    "\n",
    "            #*****Loss Function*****\n",
    "            error = y[sample]-y_hat \n",
    "            J = error**2\n",
    "            \n",
    "            #*****Backward*****\n",
    "            dJ_w11_1 = -2*error * w11_2 * dsig(z1_1) * x[sample,1]\n",
    "            dJ_w12_1 = -2*error * w11_2 * dsig(z1_1) * x[sample,0]\n",
    "            dJ_b1_1 = -2*error * w11_2 * dsig(z1_1)\n",
    "\n",
    "            dJ_w21_1 = -2*error * w12_2 * dsig(z2_1) * x[sample,1]\n",
    "            dJ_w22_1 = -2*error * w12_2 * dsig(z2_1) * x[sample,0]\n",
    "            dJ_b2_1 = -2*error * w12_2 * dsig(z2_1)\n",
    "\n",
    "            dJ_w11_2 = -2*error * a1_1\n",
    "            dJ_w12_2 = -2*error * a2_1\n",
    "            dJ_b1_2 = -2*error * 1\n",
    "\n",
    "            #*****Updates of weights*****\n",
    "\n",
    "            # Params Neurona 1 Layer 1\n",
    "            w11_1 = w11_1 - lr * dJ_w11_1\n",
    "            w12_1 = w12_1 - lr * dJ_w12_1\n",
    "            b1_1 = b1_1 - lr * dJ_b1_1\n",
    "\n",
    "            # Params Neurona 2 Layer 1\n",
    "            w21_1 = w21_1 - lr * dJ_w21_1\n",
    "            w22_1 = w22_1 - lr * dJ_w22_1\n",
    "            b2_1 = b2_1 - lr * dJ_b2_1\n",
    "\n",
    "            # Params Neurona 1 Layer 2\n",
    "            w11_2 = w11_2 - lr * dJ_w11_2\n",
    "            w12_2 = w12_2 - lr * dJ_w12_2\n",
    "            b1_2 = b1_2 - lr * dJ_b1_2\n",
    "            \n",
    "    return w11_1, w12_1, b1_1, w21_1, w22_1, b2_1, w11_2, w12_2, b1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor real: 0\tPrediccion: 0.0\tError: 1.232595164407831e-30\n",
      "Valor real: 1\tPrediccion: 1.0\tError: 1.232595164407831e-30\n",
      "Valor real: 1\tPrediccion: 1.0\tError: 1.232595164407831e-30\n",
      "Valor real: 0\tPrediccion: -0.0\tError: 1.3096323621833204e-30\n",
      "Error del modelo 3.274080905458301e-31\n"
     ]
    }
   ],
   "source": [
    "# XOR Truth Table\n",
    "y_xor = np.array([0,1,1,0])\n",
    "\n",
    "w11_1, w12_1, b1_1, w21_1, w22_1, b2_1, w11_2, w12_2, b1_2 = logic_gates_model(x, y_xor, epochs=1000, lr=0.4, eps = 1)\n",
    "test(x, y_xor, w11_1, w12_1, b1_1, w21_1, w22_1, b2_1, w11_2, w12_2, b1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor real: 0\tPrediccion: -0.0\tError: 1.740667436819862e-08\n",
      "Valor real: 0\tPrediccion: 0.0\tError: 2.2155452350171518e-08\n",
      "Valor real: 0\tPrediccion: -0.0\tError: 2.2192853272363846e-08\n",
      "Valor real: 1\tPrediccion: 1.0\tError: 7.718617567481028e-08\n",
      "Error del modelo 1.929654391870257e-08\n"
     ]
    }
   ],
   "source": [
    "# AND Truth Table\n",
    "y_and = np.array([0,0,0,1])\n",
    "\n",
    "w11_1, w12_1, b1_1, w21_1, w22_1, b2_1, w11_2, w12_2, b1_2 = logic_gates_model(x, y_and, epochs=1000, lr=0.5, eps = 1)\n",
    "test(x, y_and, w11_1, w12_1, b1_1, w21_1, w22_1, b2_1, w11_2, w12_2, b1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor real: 0\tPrediccion: 0.0\tError: 0.0023408685946813973\n",
      "Valor real: 1\tPrediccion: 1.0\tError: 0.0023417816699729224\n",
      "Valor real: 1\tPrediccion: 1.0\tError: 0.0023435720209333817\n",
      "Valor real: 1\tPrediccion: 1.0\tError: 0.0036293883123044712\n",
      "Error del modelo 0.0009073470780761178\n"
     ]
    }
   ],
   "source": [
    "# OR Truth Table\n",
    "y_or = np.array([0,1,1,1])\n",
    "\n",
    "w11_1, w12_1, b1_1, w21_1, w22_1, b2_1, w11_2, w12_2, b1_2 = logic_gates_model(x, y_or, epochs=1000, lr=0.8, eps = 1)\n",
    "test(x, y_or, w11_1, w12_1, b1_1, w21_1, w22_1, b2_1, w11_2, w12_2, b1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor real: 1\tPrediccion: 1.0\tError: 1.6498927496457985e-16\n",
      "Valor real: 0\tPrediccion: -0.0\tError: 2.8365821658883497e-16\n",
      "Valor real: 0\tPrediccion: -0.0\tError: 3.1391712558688476e-16\n",
      "Valor real: 0\tPrediccion: -0.0\tError: 1.8596044575302422e-15\n",
      "Error del modelo 4.649011143825606e-16\n"
     ]
    }
   ],
   "source": [
    "# NOR Truth Table\n",
    "y_nor = np.array([1,0,0,0])\n",
    "\n",
    "w11_1, w12_1, b1_1, w21_1, w22_1, b2_1, w11_2, w12_2, b1_2 = logic_gates_model(x, y_nor, epochs=1000, lr=0.5, eps = 1)\n",
    "test(x, y_nor, w11_1, w12_1, b1_1, w21_1, w22_1, b2_1, w11_2, w12_2, b1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor real: 1\tPrediccion: 1.0\tError: 0.0\n",
      "Valor real: 1\tPrediccion: 1.0\tError: 0.0\n",
      "Valor real: 1\tPrediccion: 1.0\tError: 0.0\n",
      "Valor real: 0\tPrediccion: 0.0\tError: 0.0\n",
      "Error del modelo 0.0\n"
     ]
    }
   ],
   "source": [
    "# NAND Truth Table\n",
    "y_nand = np.array([1,1,1,0])\n",
    "\n",
    "w11_1, w12_1, b1_1, w21_1, w22_1, b2_1, w11_2, w12_2, b1_2 = logic_gates_model(x, y_nand, epochs=1000, lr=0.5, eps = 1)\n",
    "test(x, y_nand, w11_1, w12_1, b1_1, w21_1, w22_1, b2_1, w11_2, w12_2, b1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor real: 1\tPrediccion: 1.0\tError: 0.0\n",
      "Valor real: 0\tPrediccion: 0.0\tError: 0.0\n",
      "Valor real: 0\tPrediccion: 0.0\tError: 0.0\n",
      "Valor real: 1\tPrediccion: 1.0\tError: 1.232595164407831e-32\n",
      "Error del modelo 3.0814879110195774e-33\n"
     ]
    }
   ],
   "source": [
    "# XNOR Truth Table\n",
    "y_xnor = np.array([1,0,0,1])\n",
    "\n",
    "w11_1, w12_1, b1_1, w21_1, w22_1, b2_1, w11_2, w12_2, b1_2 = logic_gates_model(x, y_xnor, epochs=1000, lr=0.4, eps = 1)\n",
    "test(x, y_xnor, w11_1, w12_1, b1_1, w21_1, w22_1, b2_1, w11_2, w12_2, b1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMg0NMuLGQxN8MNlwiCZoOt",
   "include_colab_link": true,
   "name": "Clase_1_DeepLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
